(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{377:function(a,t,e){"use strict";e.r(t);var r=e(25),n=Object(r.a)({},(function(){var a=this,t=a.$createElement,e=a._self._c||t;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h1",{attrs:{id:"计算学习理论-computational-learning-theory"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#计算学习理论-computational-learning-theory"}},[a._v("#")]),a._v(" 计算学习理论 (Computational Learning Theory)")]),a._v(" "),e("div",{staticClass:"custom-block warning"},[e("p",{staticClass:"custom-block-title"},[a._v("🚧")]),a._v(" "),e("p",[a._v("under construction...")])]),a._v(" "),e("h2",{attrs:{id:"什么是「学习」"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#什么是「学习」"}},[a._v("#")]),a._v(" 什么是「学习」")]),a._v(" "),e("p",[a._v("先定义一些概念")]),a._v(" "),e("ul",[e("li",[a._v("accent"),e("strong",[a._v("样本空间")]),a._v(" $\\mathcal{X}$，其中样本 $x$ 通常由向量表示")]),a._v(" "),e("li",[a._v("accent"),e("strong",[a._v("标记空间")]),a._v(" $\\mathcal{Y}$，考虑二分类问题时，$\\mathcal{Y} = \\lbrace+1,-1\\rbrace$ 或 $\\lbrace0,1\\rbrace$")]),a._v(" "),e("li",[a._v("$\\mathcal{X}$ 中的样本服从一个隐含未知的accent"),e("strong",[a._v("样本分布")]),a._v(" $\\mathcal{D}$（underlying data-generating distribution），即 $x\\sim\\mathcal{D}$"),e("br"),a._v("\n（有的地方 $\\mathcal{D}$ 定义在 $\\mathcal{X}\\times\\mathcal{Y}$ 之上，即 $(x,y)\\sim\\mathcal{D}$，"),e("em",[a._v("TODO")]),a._v("）")]),a._v(" "),e("li",[a._v("accent"),e("strong",[a._v("标记函数")]),a._v(" $f\\colon\\mathcal{X}\\to\\mathcal{Y}$（未知，是学习器想学习到的）"),e("br"),a._v("\n也被称为 concept，$c\\colon\\mathcal{X}\\to\\mathcal{Y}$，$c\\in\\mathcal{C}$ (concept class)")]),a._v(" "),e("li",[a._v("accent"),e("strong",[a._v("样例集")]),a._v(" $D=\\lbrace(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),\\cdots,(x^{(m)},y^{(m)})\\rbrace$：先从 $\\mathcal{D}$ 中采样 $x^{(i)}$，然后由 $f$ 标记得到 $y^{(i)}$，独立地多次采样得到样例集 $D$，这就是"),e("strong",[a._v("独立同分布")]),a._v("假设（i.i.d. assumption）")]),a._v(" "),e("li",[a._v("学习器的输出，accent"),e("strong",[a._v("假设函数")]),a._v(" $h\\colon\\mathcal{X}\\to\\mathcal{Y}$，所有可能的 $h$ 的集合叫做"),e("strong",[a._v("假设空间")]),a._v(" $\\mathcal{H}$（比如所有形如 $h=ax+b$ 的函数），$\\mathcal{H}$ 由 "),e("a",{attrs:{href:"https://en.wikipedia.org/wiki/Inductive_bias",target:"_blank",rel:"noopener noreferrer"}},[a._v("inductive bias"),e("OutboundLink")],1),a._v(" 决定（即对某类 $h$ 的偏好）")]),a._v(" "),e("li",[a._v("accent"),e("strong",[a._v("损失函数")]),a._v("（loss function），$\\ell\\colon\\mathcal{Y}\\times\\mathcal{Y}\\to\\mathbb{R}$，学习理论主要研究二分类问题，常使用 0-1 loss，即 $\\ell=1_{h(x) \\neq y}$，其中 $1$ 为指示函数")])]),a._v(" "),e("p",[a._v("得到一个 $h$ 后，我们如何评估它的好坏")]),a._v(" "),e("ul",[e("li",[a._v("accent"),e("strong",[a._v("泛化误差")]),a._v("，在样本分布 $\\mathcal{D}$ 之下 loss 的期望"),e("br"),a._v("\n$$ E(h;\\mathcal{D}) = \\mathbb{E}_{x\\sim\\mathcal{D}}\\thinspace[\\ell(h(x),y)]. $$")]),a._v(" "),e("li",[a._v("accent"),e("strong",[a._v("经验误差")]),a._v("，在样例集上的平均 loss"),e("br"),a._v(" "),e("span",[a._v("$$ \\widehat{E}(h;D)=\\frac{1}{m}\\sum_{i=1}^m \\ell\\mathopen{}\\left(h(x^{(i)}), y^{(i)}\\right)\\mathclose{}. $$")])])]),a._v(" "),e("h2",{attrs:{id:"pac-学习框架"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#pac-学习框架"}},[a._v("#")]),a._v(" PAC 学习框架")]),a._v(" "),e("h2",{attrs:{id:"vc-维"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#vc-维"}},[a._v("#")]),a._v(" VC 维")]),a._v(" "),e("h2",{attrs:{id:"阅读材料"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#阅读材料"}},[a._v("#")]),a._v(" 阅读材料")]),a._v(" "),e("ul",[e("li",[a._v("Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar. Foundations of Machine Learning. "),e("em",[a._v("The MIT Press")]),a._v(". 2012. (Chapter 2, 3)")]),a._v(" "),e("li",[a._v("周志华. 机器学习.（第 12 章，计算学习理论）")]),a._v(" "),e("li",[a._v("Shalev-Shwartz, Shai, and Shai Ben-David. Understanding machine learning: From theory to algorithms. "),e("em",[a._v("Cambridge University Press")]),a._v(". 2014. (Chapter 2, 3)")]),a._v(" "),e("li",[e("a",{attrs:{href:"https://web.stanford.edu/class/cs229t/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Stanford CS229T/STATS231: Statistical Learning Theory"),e("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=n.exports}}]);